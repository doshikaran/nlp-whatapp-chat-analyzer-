{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji\n",
    "import regex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import re\n",
    "import seaborn as sns\n",
    "from datetime import *\n",
    "import datetime as dt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import emoji\n",
    "from seaborn import *\n",
    "from wordcloud import WordCloud , STOPWORDS , ImageColorGenerator\n",
    "from nltk import *\n",
    "from plotly import express as px\n",
    "% matplotlib inline\n",
    "def startsWithDateAndTime(s):\n",
    "pattern = '^([0-9][0-9]+)(/)([0-9][0-9]+)(/)([0-9][0-9][0-9][0-9]),\n",
    "(([0-9])|([0-9][0-9])+):([0-9][0-9]) (am|pm) -'\n",
    "result = re.match(pattern, s)\n",
    "if result:\n",
    "return True\n",
    "return False\n",
    "def FindAuthor(s):\n",
    "s=s.split(\":\")\n",
    "if len(s)==2:\n",
    "return True\n",
    "else:\n",
    "return False\n",
    "def getDataPoint(line):\n",
    "splitLine = line.split(' - ')\n",
    "dateTime = splitLine[0]\n",
    "date, time = dateTime.split(', ')\n",
    "\n",
    "message = ' '.join(splitLine[1:])\n",
    "if FindAuthor(message):\n",
    "splitMessage = message.split(': ')\n",
    "author = splitMessage[0]\n",
    "message = ' '.join(splitMessage[1:])\n",
    "else:\n",
    "author = None\n",
    "return date, time, author, message\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "parsedData = [] # List to keep track of data so it can be used by a Pandas\n",
    "dataframe\n",
    "conversation = '/content/gdrive/MyDrive/NLP/WhatsApp Chat with BE Project\n",
    "Group 1 .txt'\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "fp.readline() # Skipping first line of the file because contains\n",
    "information related to something about end-to-end encryption\n",
    "messageBuffer = []\n",
    "date, time, author = None, None, None\n",
    "while True:\n",
    "line = fp.readline()\n",
    "if not line:\n",
    "break\n",
    "line = line.strip()\n",
    "if startsWithDateAndTime(line):\n",
    "if len(messageBuffer) > 0:\n",
    "parsedData.append([date, time, author, '\n",
    "\n",
    "'.join(messageBuffer)])\n",
    "\n",
    "messageBuffer.clear()\n",
    "date, time, author, message = getDataPoint(line)\n",
    "messageBuffer.append(message)\n",
    "else:\n",
    "messageBuffer.append(line)\n",
    "\n",
    "df = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Author',\n",
    "'Message']) # Initialising a pandas Dataframe.\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.head(10)\n",
    "df.Author.unique()\n",
    "### Checking shape of dataset.\n",
    "df.shape\n",
    "### Checking basic information of dataset\n",
    "df.info()\n",
    "### Checking no. of null values in dataset\n",
    "df.isnull().sum()\n",
    "### Checking head part of dataset\n",
    "df.head(50)\n",
    "### Checking tail part of dataset\n",
    "df.tail(50)\n",
    "### Droping Nan values from dataset\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape\n",
    "### Checking no. of authors of group\n",
    "df['Author'].nunique()\n",
    "### Checking authors of group\n",
    "df['Author'].unique()\n",
    "\n",
    "media_messages = df[df['Message'] == '<Media omitted>'].shape[0]\n",
    "print(media_messages)\n",
    "def split_count(text):\n",
    "emoji_list = []\n",
    "data = regex.findall(r'\\X', text)\n",
    "for word in data:\n",
    "if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "emoji_list.append(word)\n",
    "\n",
    "return emoji_list\n",
    "df[\"emoji\"] = df[\"Message\"].apply(split_count)\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "print(emojis)\n",
    "URLPATTERN = r'(https?://\\S+)'\n",
    "\n",
    "df['urlcount'] = df.Message.apply(lambda x: re.findall(URLPATTERN,\n",
    "x)).str.len()\n",
    "links = np.sum(df.urlcount)\n",
    "print(\"Data science Community\")\n",
    "print(\"Media:\",media_messages)\n",
    "print(\"Emojis:\",emojis)\n",
    "print(\"Links:\",links)\n",
    "\n",
    "### Adding one more column of \"Day\" for better analysis, here we use\n",
    "datetime library which help us to do this task easily.\n",
    "weeks = {\n",
    "0 : 'Monday',\n",
    "1 : 'Tuesday',\n",
    "2 : 'Wednesday',\n",
    "3 : 'Thrusday',\n",
    "4 : 'Friday',\n",
    "5 : 'Saturday',\n",
    "6 : 'Sunday'\n",
    "}\n",
    "df['Day'] = df['Date'].dt.weekday.map(weeks)\n",
    "\n",
    "### Rearranging the columns for better understanding\n",
    "df = df[['Date','Day','Time','Author','Message']]\n",
    "### Changing the datatype of column \"Day\".\n",
    "df['Day'] = df['Day'].astype('category')\n",
    "### Looking newborn dataset.\n",
    "df.head()\n",
    "### Counting number of letters in each message\n",
    "df['Letters'] = df['Message'].apply(lambda s : len(s))\n",
    "### Counting number of word's in each message\n",
    "df['Words'] = df['Message'].apply(lambda s : len(s.split(' ')))\n",
    "### Function to count number of links in dataset, it will add extra column\n",
    "and store information in it.\n",
    "URLPATTERN = r'(https?://S+)'\n",
    "df['Url_Count'] = df.Message.apply(lambda x: re.findall(URLPATTERN,\n",
    "x)).str.len()\n",
    "links = np.sum(df.Url_Count)\n",
    "### Function to count number of media in chat.\n",
    "MEDIAPATTERN = r'<Media omitted>'\n",
    "df['Media_Count'] = df.Message.apply(lambda x : re.findall(MEDIAPATTERN,\n",
    "x)).str.len()\n",
    "media = np.sum(df.Media_Count)\n",
    "### Looking updated dataset\n",
    "df\n",
    "\n",
    "df.tail(10)\n",
    "\n",
    "total_messages = df.shape[0]\n",
    "media_messages = df[df['Message'] == '<Media omitted>'].shape[0]\n",
    "links = np.sum(df.Url_Count)\n",
    "print('Group Chatting Stats : ')\n",
    "print('Total Number of Messages : {}'.format(total_messages))\n",
    "print('Total Number of Media Messages : {}'.format(media_messages))\n",
    "print('Total Number of Links : {}'.format(links))\n",
    "\n",
    "l = df.Author.unique()\n",
    "for i in range(len(l)):\n",
    "### Filtering out messages of particular user\n",
    "req_df = df[df[\"Author\"] == l[i]]\n",
    "### req_df will contain messages of only one particular user\n",
    "print(f'--> Stats of {l[i]} <-- ')\n",
    "### shape will print number of rows which indirectly means the number of\n",
    "messages\n",
    "print('Total Message Sent : ', req_df.shape[0])\n",
    "### Word_Count contains of total words in one message. Sum of all words/\n",
    "Total Messages will yield words per message\n",
    "\n",
    "words_per_message = (np.sum(req_df['Words']))/req_df.shape[0]\n",
    "w_p_m = (\"%.3f\" % round(words_per_message, 2))\n",
    "print('Average Words per Message : ', w_p_m)\n",
    "### media conists of media messages\n",
    "media = sum(req_df[\"Media_Count\"])\n",
    "print('Total Media Message Sent : ', media)\n",
    "### links consist of total links\n",
    "links = sum(req_df[\"Url_Count\"])\n",
    "print('Total Links Sent : ', links)\n",
    "print()\n",
    "print('----------------------------------------------------------\\n')\n",
    "\n",
    "### Word Cloud of mostly used word in our Group\n",
    "text = \" \".join(review for review in df.Message)\n",
    "wordcloud = WordCloud(stopwords=STOPWORDS,\n",
    "background_color=\"white\").generate(text)\n",
    "### Display the generated image:\n",
    "\n",
    "plt.figure( figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "### Creates a list of unique Authors\n",
    "l = df.Author.unique()\n",
    "for i in range(len(l)):\n",
    "### Filtering out messages of particular user\n",
    "req_df = df[df[\"Author\"] == l[i]]\n",
    "### req_df will contain messages of only one particular user\n",
    "print(l[i],' -> ',req_df.shape[0])\n",
    "\n",
    "l = df.Day.unique()\n",
    "for i in range(len(l)):\n",
    "### Filtering out messages of particular user\n",
    "req_df = df[df[\"Day\"] == l[i]]\n",
    "### req_df will contain messages of only one particular user\n",
    "print(l[i],' -> ',req_df.shape[0])\n",
    "\n",
    "### Mostly Active Member in the Group\n",
    "plt.figure(figsize=(9,6))\n",
    "mostly_active = df['Author'].value_counts()\n",
    "### Top 10 peoples that are mostly active in our Group is :\n",
    "m_a = mostly_active.head(10)\n",
    "bars = ['Kalpita Maam','Sneha Satish','Saloni Dhotre','Karan Doshi']\n",
    "x_pos = np.arange(len(bars))\n",
    "m_a.plot.bar()\n",
    "plt.xlabel('Authors',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.title('Mostly active member of Group',fontdict={'fontsize':\n",
    "20,'fontweight': 8})\n",
    "plt.xticks(x_pos, bars)\n",
    "plt.show()\n",
    "\n",
    "### Mostly Active day in the Group\n",
    "plt.figure(figsize=(8,5))\n",
    "active_day = df['Day'].value_counts()\n",
    "### Top 10 peoples that are mostly active in our Group is :\n",
    "a_d = active_day.head(10)\n",
    "a_d.plot.bar()\n",
    "plt.xlabel('Day',fontdict={'fontsize': 12,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 12,'fontweight': 10})\n",
    "plt.title('Mostly active day of Week in the Group',fontdict={'fontsize':\n",
    "18,'fontweight': 8})\n",
    "plt.show()\n",
    "\n",
    "### Top Media Contributor of Group\n",
    "mm = df[df['Message'] == '<Media omitted>']\n",
    "mm1 = mm['Author'].value_counts()\n",
    "bars = ['Kalpita Maam','Sneha Satish','Saloni Dhotre','Karan Doshi']\n",
    "x_pos = np.arange(len(bars))\n",
    "top10 = mm1.head(10)\n",
    "top10.plot.bar()\n",
    "plt.xlabel('Authors',fontdict={'fontsize': 12,'fontweight': 10})\n",
    "plt.ylabel('No. of media',fontdict={'fontsize': 12,'fontweight': 10})\n",
    "plt.title('Top media contributor of Group',fontdict={'fontsize':\n",
    "18,'fontweight': 8})\n",
    "plt.xticks(x_pos, bars)\n",
    "plt.show()\n",
    "\n",
    "max_words = df[['Author','Words']].groupby('Author').sum()\n",
    "m_w = max_words.sort_values('Words',ascending=False).head(10)\n",
    "bars = ['Kalpita Maam','Sneha Satish','Saloni Dhotre','Karan Doshi']\n",
    "x_pos = np.arange(len(bars))\n",
    "m_w.plot.bar(rot=90)\n",
    "plt.xlabel('Author')\n",
    "plt.ylabel('No. of words')\n",
    "plt.title('Analysis of members who has used max. no. of words in his/her\n",
    "messages')\n",
    "plt.xticks(x_pos, bars)\n",
    "plt.show()\n",
    "\n",
    "### Member who has shared max numbers of link in Group\n",
    "max_words = df[['Author','Url_Count']].groupby('Author').sum()\n",
    "m_w = max_words.sort_values('Url_Count',ascending=False).head(10)\n",
    "bars = ['Kalpita Maam','Sneha Satish','Saloni Dhotre','Karan Doshi']\n",
    "x_pos = np.arange(len(bars))\n",
    "m_w.plot.bar(rot=90)\n",
    "plt.xlabel('Author')\n",
    "plt.ylabel('No. of links')\n",
    "plt.title('Analysis of members who has shared max no. of links in Group')\n",
    "plt.xticks(x_pos, bars)\n",
    "plt.show()\n",
    "\n",
    "### Time whenever our group is highly active\n",
    "plt.figure(figsize=(8,5))\n",
    "t = df['Time'].value_counts().head(20)\n",
    "tx = t.plot.bar()\n",
    "tx.yaxis.set_major_locator(MaxNLocator(integer=True)) #Converting y axis\n",
    "data to integer\n",
    "plt.xlabel('Time',fontdict={'fontsize': 12,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 12,'fontweight': 10})\n",
    "plt.title('Analysis of time when Group was highly\n",
    "active.',fontdict={'fontsize': 18,'fontweight': 8})\n",
    "plt.show()\n",
    "\n",
    "lst = []\n",
    "for i in df['Time'] :\n",
    "out_time = datetime.strftime(datetime.strptime(i,\"%I:%M %p\"),\"%H:%M\")\n",
    "lst.append(out_time)\n",
    "df['24H_Time'] = lst\n",
    "df['Hours'] = df['24H_Time'].apply(lambda x : x.split(':')[0])\n",
    "### Most suitable hour of day, whenever there will more chances of getting\n",
    "response from group members.\n",
    "plt.figure(figsize=(8,5))\n",
    "std_time = df['Hours'].value_counts().head(15)\n",
    "s_T = std_time.plot.bar()\n",
    "s_T.yaxis.set_major_locator(MaxNLocator(integer=True)) #Converting y axis\n",
    "data to integer\n",
    "plt.xlabel('Hours (24-Hour)',fontdict={'fontsize': 12,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 12,'fontweight': 10})\n",
    "plt.title('Most suitable hour of day.',fontdict={'fontsize':\n",
    "18,'fontweight': 8})\n",
    "plt.show()\n",
    "\n",
    "active_m = df['Author'].unique()\n",
    "for i in range(len(active_m)) :\n",
    "# Filtering out messages of particular user\n",
    "m_chat = df[df[\"Author\"] == active_m[i]]\n",
    "print(f'--- Author : {active_m[i]} --- ')\n",
    "# Word Cloud of mostly used word in our Group\n",
    "msg = ' '.join(x for x in m_chat.Message)\n",
    "wordcloud = WordCloud(stopwords=STOPWORDS,\n",
    "background_color=\"white\").generate(msg)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print('___________________________________________________________________\n",
    "_________________\\n')\n",
    "\n",
    "### Date on which our Group was highly active.\n",
    "plt.figure(figsize=(8,5))\n",
    "df['Date'].value_counts().head(15).plot.bar()\n",
    "plt.xlabel('Date',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.title('Analysis of Date on which Group was highly\n",
    "active',fontdict={'fontsize': 18,'fontweight': 8})\n",
    "plt.show()\n",
    "\n",
    "z = df['Date'].value_counts()\n",
    "z1 = z.to_dict() #converts to dictionary\n",
    "df['Msg_count'] = df['Date'].map(z1)\n",
    "### Timeseries plot\n",
    "fig = px.line(x=df['Date'],y=df['Msg_count'])\n",
    "fig.update_layout(title='Analysis of number of messages using TimeSeries\n",
    "plot.',\n",
    "\n",
    "xaxis_title='Month',\n",
    "yaxis_title='No. of Messages')\n",
    "\n",
    "fig.update_xaxes(nticks=20)\n",
    "fig.show()\n",
    "\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Mon'] = df['Date'].dt.month\n",
    "months = {\n",
    "1 : 'Jan',\n",
    "2 : 'Feb',\n",
    "3 : 'Mar',\n",
    "4 : 'Apr',\n",
    "5 : 'May',\n",
    "6 : 'Jun',\n",
    "7 : 'Jul',\n",
    "8 : 'Aug',\n",
    "9 : 'Sep',\n",
    "10 : 'Oct',\n",
    "11 : 'Nov',\n",
    "12 : 'Dec'\n",
    "}\n",
    "df['Month'] = df['Mon'].map(months)\n",
    "df.drop('Mon',axis=1,inplace=True)\n",
    "### Mostly Active month\n",
    "plt.figure(figsize=(12,6))\n",
    "active_month = df['Month'].value_counts()\n",
    "a_m = active_month\n",
    "a_m.plot.bar()\n",
    "plt.xlabel('Month',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.title('Analysis of mostly active month.',fontdict={'fontsize': 20,\n",
    "\n",
    "'fontweight': 8})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### Mostly Active month\n",
    "plt.figure(figsize=(12,6))\n",
    "active_month = df['Year'].value_counts()\n",
    "a_m = active_month\n",
    "a_m.plot.bar()\n",
    "plt.xlabel('Month',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.title('Analysis of mostly active month.',fontdict={'fontsize': 20,\n",
    "\n",
    "'fontweight': 8})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "z = df['Month'].value_counts()\n",
    "z1 = z.to_dict() #converts to dictionary\n",
    "df['Msg_count_monthly'] = df['Month'].map(z1)\n",
    "plt.figure(figsize=(18,9))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data=df,x='Month',y='Msg_count_monthly',markers=True,marker='\n",
    "o')\n",
    "plt.xlabel('Month',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.title('Analysis of mostly active month using line\n",
    "plot.',fontdict={'fontsize': 20,'fontweight': 8})\n",
    "plt.show()\n",
    "\n",
    "z = df['Year'].value_counts()\n",
    "z1 = z.to_dict() #converts to dictionary\n",
    "df['Msg_count_monthly'] = df['Year'].map(z1)\n",
    "plt.figure(figsize=(18,9))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data=df,x='Year',y='Msg_count_monthly',markers=True,marker='o\n",
    "')\n",
    "plt.xlabel('Month',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.title('Analysis of mostly active month using line\n",
    "plot.',fontdict={'fontsize': 20,'fontweight': 8})\n",
    "plt.show()\n",
    "\n",
    "### Total message per year\n",
    "### As we analyse that the group was created in mid 2019, thats why number\n",
    "of messages in 2019 is less.\n",
    "plt.figure(figsize=(12,6))\n",
    "active_month = df['Year'].value_counts()\n",
    "a_m = active_month\n",
    "a_m.plot.bar()\n",
    "plt.xlabel('Year',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.ylabel('No. of messages',fontdict={'fontsize': 14,'fontweight': 10})\n",
    "plt.title('Analysis of mostly active year.',fontdict={'fontsize':\n",
    "20,'fontweight': 8})\n",
    "plt.show()\n",
    "\n",
    "df2 = df.groupby(['Hours', 'Day'], as_index=False)[\"Message\"].count()\n",
    "df2 = df2.dropna()\n",
    "df2.reset_index(drop = True,inplace = True)\n",
    "### Analysing on which time group is mostly active based on hours and day.\n",
    "analysis_2_df = df.groupby(['Hours', 'Day'],\n",
    "as_index=False)[\"Message\"].count()\n",
    "### Droping null values\n",
    "analysis_2_df.dropna(inplace=True)\n",
    "analysis_2_df.sort_values(by=['Message'],ascending=False)\n",
    "\n",
    "day_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thrusday', 'Friday',\n",
    "'Saturday', 'Sunday']\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "sns.heatmap(\n",
    "df2,\n",
    "x=analysis_2_df['Hours'],\n",
    "y=analysis_2_df['Day'],\n",
    "size_scale = 500,\n",
    "size = analysis_2_df['Message'],\n",
    "y_order = day_of_week[::-1],\n",
    "color = analysis_2_df['Message'],\n",
    "palette = sns.cubehelix_palette(128)\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
